/*
 * This file contains a class to hold the information about the connections between
 * layers of neurons in the network.
 *
 * Developed from FeedForwardConn.h with intention of generalising to non-perceptron models.
 *
 * \author Seb James
 * \date March 2022
 */
#pragma once

#include <morph/vVector.h>
#include <iostream>
#include <sstream>
#include <ostream>
#include <vector>
#include "conn.h"

namespace morph {
    namespace nn {

        /*
         * A connection between neuron layers in a feed forward neural network. This
         * connects any number of input neuron populations to a single output
         * population.
         */
        template <typename T>
        struct NetConn
        {
            // Construct for connection from single input layer to single output layer
            NetConn (morph::vVector<T>* _in, morph::vVector<T>* _out)
            {
                this->in = _in;
                this->commonInit (_out);
            }

            // Init common to all constructors
            void commonInit (morph::vVector<T>* _out)
            {
                this->out = _out;
                this->N = _out->size();
                this->ws.resize (this->out->size());
                this->b.resize (N, T{0});
                this->z.resize (N, T{0});
                this->z.zero();
            }

            // Points to input population's output storage
            morph::vVector<T>* in;

            // The 'activation' of this connection. This is the weights-times-the-inputs
            // and becomes the output of this connection net that is fed into the output
            // population's input. Glad we got that straight.
            morph::vVector<T> z;

            // This points to the output population's input storage.
            morph::vVector<T>* out;

            // The size (i.e. number of neurons) in z.
            size_t N = 0;

            // Weights. This is a sorted version of the weights generated by the
            // script. Outer vector is the same length as the output population's
            // outputs
            std::vector<std::vector<conn<T>>> ws;
            // Biases. Size N. Used in feedforward nets. Here they could be used for connection noise.
            morph::vVector<T> b;

            // Output as a string
            std::string str() const
            {
                std::stringstream ss;
                ss << "Connection: From input layer of size " << in->size() << ", ";
                ss << "to an output for this connection of size " << z.size() << "\n";
                size_t ci = 0;
                for (auto w : this->ws) {
                    ss << " Input " << ci++ << ": Weights: w";
                    for (auto ww : w) {
                        ss << ww.i << "->" << ww.j << ",";
                    }
                    ss << "w (" << w.size() << ")\n";
                }
                ss << "z = " << z << std::endl;
                return ss.str();
            }

            void setweight (std::vector<conn<T>>& weight_table)
            {
                // weight table is: i, j, w
                // ws is vector<vector<conn<>>>
                for (auto wt : weight_table) {
                    // wt.i -> wt.j with wt.w. ws is indexed by wt.j, the output index
                    this->ws[wt.j].push_back (wt);
                }
            }

            // Set weight/bias to a scalar for all connections
            void setweight_alltoall (T _w) {
                // Create an all-to-one connection vector:
                std::vector<conn<T>> all_connect (this->in->size());
                for (size_t i = 0; i < this->in->size(); ++i) {
                    all_connect[i] = {i, 0, _w};
                }
                size_t j = 0; // Index into the output
                for (auto& w : this->ws) {
                    // Update the all-to-one to connect the right 'one'
                    for (size_t i = 0; i < this->in->size(); ++i) {
                        all_connect[i].j = j;
                    }
                    // Copy it into ws:
                    std::copy (all_connect.begin(), all_connect.end(), w.begin());
                    j++; // Next 'one'
                }
            }

            // One to one based on index, not distance (for distance, set up
            // weight_table externally and use void setweight(std::vector<conn<T>>&))
            void setweight_onetoone (T _w) {
                // Create a all-to-none connection vector:
                conn<T> _connect = {0, 0, _w};

                size_t j = 0; // Index into the output
                for (auto& w : this->ws) {
                    // Update the all-to-none to be one-to-one
                    _connect.i = j;
                    _connect.j = j;
                    // Copy it into ws:
                    w.resize(1);
                    w[0] = _connect;
                    j++; // Next 'one'
                }
            }

            void setbias(T _b) { this->b.set_from(_b); }

            // Feed-forward compute. z[i] = in[0,..,M-1] . w[i,..,i+M-1] + b[i] (but
            // have to loop over each input population)
            void feedforward()
            {
                this->z.zero();
                // For each output:
                for (size_t j = 0; j < this->N; ++j) {
                    // Add up inputs based on this->ws[i] which is a vector<conn<T>>
                    // Adding to z[j] here.
//#pragma omp parallel for
                    for (auto c : ws[j]) {
                        // we have c.i c.j c.w, but c.j should be j, due to sorting
                        z[j] += (*this->in)[c.i] * c.w;
                    }
                }

                // For each activation, z, apply the transfer function to generate the output, out
                this->applyTransfer(); // Now this ONLY adds the biases
            }

            // For each activation, z, add the bias, then apply the sigmoid transfer function
            void applyTransfer()
            {
                auto biter = this->b.begin();
//#pragma omp parallel for
                for (size_t j = 0; j < this->N; ++j) {
                    this->z[j] += *biter++;
                }
            }
        };

        // Stream operator
        template <typename T>
        std::ostream& operator<< (std::ostream& os, const NetConn<T>& c)
        {
            os << c.str();
            return os;
        }

    } // namespace nn
} // namespace morph
