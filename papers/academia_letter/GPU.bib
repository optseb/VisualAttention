
@article{cope_spinecreator:_2016,
	title = {{SpineCreator}: a {Graphical} {User} {Interface} for the {Creation} of {Layered} {Neural} {Models}},
	issn = {1539-2791, 1559-0089},
	shorttitle = {{SpineCreator}},
	url = {http://link.springer.com/10.1007/s12021-016-9311-z},
	doi = {10.1007/s12021-016-9311-z},
	language = {en},
	urldate = {2016-10-04},
	journal = {Neuroinformatics},
	author = {Cope, A. J. and Richmond, P. and James, S. S. and Gurney, K. and Allerton, D. J.},
	month = sep,
	year = {2016},
	file = {Cope et al. - 2016 - SpineCreator a Graphical User Interface for the C.pdf:/home/seb/Zotero/storage/R5ZSF4F8/Cope et al. - 2016 - SpineCreator a Graphical User Interface for the C.pdf:application/pdf}
}

@article{dinkelbach_comparison_2012,
	title = {Comparison of {GPU}-and {CPU}-implementations of mean-firing rate neural networks on parallel hardware},
	volume = {23},
	url = {http://informahealthcare.com/doi/abs/10.3109/0954898X.2012.739292},
	number = {4},
	urldate = {2014-09-19},
	journal = {Network: Computation in Neural Systems},
	author = {Dinkelbach, Helge Ülo and Vitay, Julien and Beuth, Frederik and Hamker, Fred H.},
	year = {2012},
	pages = {212--236},
	file = {0954898X.2012.pdf:/home/seb/Zotero/storage/M3CSXT48/0954898X.2012.pdf:application/pdf}
}

@article{james_integrating_2018,
	title = {Integrating {Brain} and {Biomechanical} {Models}—{A} {New} {Paradigm} for {Understanding} {Neuro}-muscular {Control}},
	volume = {12},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00039/full},
	doi = {10.3389/fnins.2018.00039},
	abstract = {To date, realistic models of how the central nervous system governs behaviour have been restricted in scope to the brain, brainstem or spinal column, as if these existed as disembodied organs. Further, the model is often exercised in relation to an in vivo physiological experiment with input comprising an impulse, a periodic signal or constant activation, and output as a pattern of neural activity in one or more neural populations. Any link to behaviour is inferred only indirectly via these activity patterns. We argue that to discover the principles of operation of neural systems, it is necessary to express their behaviour in terms of physical movements of a realistic motor system, and to supply inputs that mimic sensory experience. To do this with confidence, we must connect our brain models to neuro-muscular models and provide relevant visual and proprioceptive feedback signals, thereby closing the loop of the simulation. This paper describes an effort to develop just such an integrated brain and biomechanical system using a number of pre-existing models. It describes a model of the saccadic oculomotor system incorporating a neuromuscular model of the eye and its six extraocular muscles. The position of the eye determines how illumination of a retinotopic input population projects information about the location of a saccade target into the system. A pre-existing saccadic burst generator model was incorporated into the system, which generated motoneuron activity patterns suitable for driving the biomechanical eye. The model was demonstrated to make accurate saccades to a target luminance under a set of environmental constraints. Challenges encountered in the development of this model showed the importance of this integrated modelling approach. Thus, we exposed shortcomings in individual model components which were only apparent when these were supplied with the more plausible inputs available in a closed loop design. Consequently we were able to suggest missing functionality which the system would require to reproduce more realistic behaviour. The construction of such closed-loop animal models constitutes a new paradigm of computational neurobehaviour and promises a more thoroughgoing approach to our understanding of the brain's function as a controller for movement and behaviour.},
	language = {English},
	urldate = {2018-02-14},
	journal = {Frontiers in Neuroscience},
	author = {James, Sebastian S. and Papapavlou, Chris and Blenkinsop, Alexander and Cope, Alexander J. and Anderson, Sean R. and Moustakas, Konstantinos and Gurney, Kevin N.},
	year = {2018},
	keywords = {Biomechanics, Basal Ganglia, Saccades, Oculomotor Muscles, integrated brain and biomechanics, Neuromuscular Junction},
	file = {James et al. - 2018 - Integrating Brain and Biomechanical Models—A New P.pdf:/home/seb/Zotero/storage/F6J2QZTY/James et al. - 2018 - Integrating Brain and Biomechanical Models—A New P.pdf:application/pdf}
}

@article{avramidis_optimisation_2017,
	title = {Optimisation of an exemplar oculomotor model using multi-objective genetic algorithms executed on a {GPU}-{CPU} combination},
	volume = {11},
	issn = {1752-0509},
	url = {https://doi.org/10.1186/s12918-017-0416-2},
	doi = {10.1186/s12918-017-0416-2},
	abstract = {Parameter optimisation is a critical step in the construction of computational biology models. In eye movement research, computational models are increasingly important to understanding the mechanistic basis of normal and abnormal behaviour. In this study, we considered an existing neurobiological model of fast eye movements (saccades), capable of generating realistic simulations of: (i) normal horizontal saccades; and (ii) infantile nystagmus – pathological ocular oscillations that can be subdivided into different waveform classes. By developing appropriate fitness functions, we optimised the model to existing experimental saccade and nystagmus data, using a well-established multi-objective genetic algorithm. This algorithm required the model to be numerically integrated for very large numbers of parameter combinations. To address this computational bottleneck, we implemented a master-slave parallelisation, in which the model integrations were distributed across the compute units of a GPU, under the control of a CPU.},
	urldate = {2018-02-09},
	journal = {BMC Systems Biology},
	author = {Avramidis, Eleftherios and Akman, Ozgur E.},
	month = mar,
	year = {2017},
	keywords = {High-performance computing, Infantile nystagmus, Mathematical modelling, Multi-objective genetic algorithms, Oculomotor control, Parameter optimisation, Systems biology},
	pages = {40},
	file = {Full Text PDF:/home/seb/Zotero/storage/ULYR8CWC/Avramidis and Akman - 2017 - Optimisation of an exemplar oculomotor model using.pdf:application/pdf;Snapshot:/home/seb/Zotero/storage/RDNQ2326/s12918-017-0416-2.html:text/html}
}

@misc{cope_spineml_2014,
	title = {{SpineML}},
	url = {https://github.com/SpineML/spineml/},
	author = {Cope, Alex and Richmond, Paul},
	year = {2014},
	note = {RRID: SCR\_015641}
}

@misc{cope_spinecreator_2015,
	title = {{SpineCreator}},
	copyright = {GNU GPL},
	url = {https://github.com/SpineML/SpineCreator},
	abstract = {A Graphical User Interface for the development of neural network models which writes the models out in the SpineML declarative markup language.},
	author = {Cope, A. J. and Richmond, P. and James, S. S.},
	year = {2015},
	note = {RRID: SCR\_015637}
}

@article{stimberg_brian2genn_2020,
	title = {{Brian2GeNN}: accelerating spiking neural network simulations with graphics hardware},
	volume = {10},
	copyright = {2020 The Author(s)},
	issn = {2045-2322},
	shorttitle = {{Brian2GeNN}},
	url = {https://www.nature.com/articles/s41598-019-54957-7},
	doi = {10.1038/s41598-019-54957-7},
	abstract = {“Brian” is a popular Python-based simulator for spiking neural networks, commonly used in computational neuroscience. GeNN is a C++-based meta-compiler for accelerating spiking neural network simulations using consumer or high performance grade graphics processing units (GPUs). Here we introduce a new software package, Brian2GeNN, that connects the two systems so that users can make use of GeNN GPU acceleration when developing their models in Brian, without requiring any technical knowledge about GPUs, C++ or GeNN. The new Brian2GeNN software uses a pipeline of code generation to translate Brian scripts into C++ code that can be used as input to GeNN, and subsequently can be run on suitable NVIDIA GPU accelerators. From the user’s perspective, the entire pipeline is invoked by adding two simple lines to their Brian scripts. We have shown that using Brian2GeNN, two non-trivial models from the literature can run tens to hundreds of times faster than on CPU.},
	language = {en},
	number = {1},
	urldate = {2020-10-01},
	journal = {Scientific Reports},
	author = {Stimberg, Marcel and Goodman, Dan F. M. and Nowotny, Thomas},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {410},
	file = {Full Text PDF:/home/seb/Zotero/storage/Y6N3YYFG/Stimberg et al. - 2020 - Brian2GeNN accelerating spiking neural network si.pdf:application/pdf;Snapshot:/home/seb/Zotero/storage/ESLBC6JF/s41598-019-54957-7.html:text/html}
}

@article{mnih_playing_2013,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	abstract = {We present the ﬁrst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We ﬁnd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	language = {en},
	urldate = {2020-10-09},
	journal = {arXiv:1312.5602 [cs]},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.5602},
	keywords = {Computer Science - Machine Learning},
	file = {Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:/home/seb/Zotero/storage/QJ7S2LTZ/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf}
}

@article{bojarski_end_2016,
	title = {End to {End} {Learning} for {Self}-{Driving} {Cars}},
	url = {http://arxiv.org/abs/1604.07316},
	abstract = {We trained a convolutional neural network (CNN) to map raw pixels from a single front-facing camera directly to steering commands. This end-to-end approach proved surprisingly powerful. With minimum training data from humans the system learns to drive in traffic on local roads with or without lane markings and on highways. It also operates in areas with unclear visual guidance such as in parking lots and on unpaved roads. The system automatically learns internal representations of the necessary processing steps such as detecting useful road features with only the human steering angle as the training signal. We never explicitly trained it to detect, for example, the outline of roads. Compared to explicit decomposition of the problem, such as lane marking detection, path planning, and control, our end-to-end system optimizes all processing steps simultaneously. We argue that this will eventually lead to better performance and smaller systems. Better performance will result because the internal components self-optimize to maximize overall system performance, instead of optimizing human-selected intermediate criteria, e.g., lane detection. Such criteria understandably are selected for ease of human interpretation which doesn't automatically guarantee maximum system performance. Smaller networks are possible because the system learns to solve the problem with the minimal number of processing steps. We used an NVIDIA DevBox and Torch 7 for training and an NVIDIA DRIVE(TM) PX self-driving car computer also running Torch 7 for determining where to drive. The system operates at 30 frames per second (FPS).},
	urldate = {2020-10-09},
	journal = {arXiv:1604.07316 [cs]},
	author = {Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.07316},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/seb/Zotero/storage/DSEWM3DU/Bojarski et al. - 2016 - End to End Learning for Self-Driving Cars.pdf:application/pdf;arXiv.org Snapshot:/home/seb/Zotero/storage/647U8X58/1604.html:text/html}
}

@article{bojarski_explaining_2017,
	title = {Explaining {How} a {Deep} {Neural} {Network} {Trained} with {End}-to-{End} {Learning} {Steers} a {Car}},
	url = {http://arxiv.org/abs/1704.07911},
	abstract = {As part of a complete software stack for autonomous driving, NVIDIA has created a neural-network-based system, known as PilotNet, which outputs steering angles given images of the road ahead. PilotNet is trained using road images paired with the steering angles generated by a human driving a data-collection car. It derives the necessary domain knowledge by observing human drivers. This eliminates the need for human engineers to anticipate what is important in an image and foresee all the necessary rules for safe driving. Road tests demonstrated that PilotNet can successfully perform lane keeping in a wide variety of driving conditions, regardless of whether lane markings are present or not. The goal of the work described here is to explain what PilotNet learns and how it makes its decisions. To this end we developed a method for determining which elements in the road image most influence PilotNet's steering decision. Results show that PilotNet indeed learns to recognize relevant objects on the road. In addition to learning the obvious features such as lane markings, edges of roads, and other cars, PilotNet learns more subtle features that would be hard to anticipate and program by engineers, for example, bushes lining the edge of the road and atypical vehicle classes.},
	urldate = {2020-10-09},
	journal = {arXiv:1704.07911 [cs]},
	author = {Bojarski, Mariusz and Yeres, Philip and Choromanska, Anna and Choromanski, Krzysztof and Firner, Bernhard and Jackel, Lawrence and Muller, Urs},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.07911},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning, Computer Science - Robotics},
	file = {arXiv Fulltext PDF:/home/seb/Zotero/storage/QC2PRD7I/Bojarski et al. - 2017 - Explaining How a Deep Neural Network Trained with .pdf:application/pdf;arXiv.org Snapshot:/home/seb/Zotero/storage/ZL28S94K/1704.html:text/html}
}

@inproceedings{david_deepchess_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{DeepChess}: {End}-to-{End} {Deep} {Neural} {Network} for {Automatic} {Learning} in {Chess}},
	isbn = {978-3-319-44781-0},
	shorttitle = {{DeepChess}},
	doi = {10.1007/978-3-319-44781-0_11},
	abstract = {We present an end-to-end learning method for chess, relying on deep neural networks. Without any a priori knowledge, in particular without any knowledge regarding the rules of chess, a deep neural network is trained using a combination of unsupervised pretraining and supervised training. The unsupervised training extracts high level features from a given position, and the supervised training learns to compare two chess positions and select the more favorable one. The training relies entirely on datasets of several million chess games, and no further domain specific knowledge is incorporated.The experiments show that the resulting neural network (referred to as DeepChess) is on a par with state-of-the-art chess playing programs, which have been developed through many years of manual feature selection and tuning. DeepChess is the first end-to-end machine learning-based method that results in a grandmaster-level chess playing performance.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2016},
	publisher = {Springer International Publishing},
	author = {David, Omid E. and Netanyahu, Nathan S. and Wolf, Lior},
	editor = {Villa, Alessandro E.P. and Masulli, Paolo and Pons Rivero, Antonio Javier},
	year = {2016},
	keywords = {Chess Game, Deep Belief Network, Deep Neural Network, High Level Feature, Supervise Training},
	pages = {88--96},
	file = {Submitted Version:/home/seb/Zotero/storage/PZMWMBIJ/David et al. - 2016 - DeepChess End-to-End Deep Neural Network for Auto.pdf:application/pdf}
}

@article{thrun_learning_1995,
	title = {Learning to {Play} the {Game} of {Chess}},
	abstract = {This paper presents NeuroChess, a program which learns to play chess from the final outcome of games. NeuroChess learns chess board evaluation functions, represented by artificial neural networks. It integrates inductive neural network learning, temporal differencing, and a variant of explanation-based learning. Performance results illustrate some of the strengths and weaknesses of this approach.},
	language = {en},
	journal = {Advances in neural information processing systems.},
	author = {Thrun, Sebastian},
	year = {1995},
	pages = {1069--1076},
	file = {Thrun - Learning to Play the Game of Chess.pdf:/home/seb/Zotero/storage/HS7DXS89/Thrun - Learning to Play the Game of Chess.pdf:application/pdf}
}

@article{silver_general_2018,
	title = {A general reinforcement learning algorithm that masters chess, shogi, and {Go} through self-play},
	volume = {362},
	copyright = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/362/6419/1140},
	doi = {10.1126/science.aar6404},
	abstract = {One program to rule them all
Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.
Science, this issue p. 1140; see also pp. 1087 and 1118
The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.
AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each.
AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each.},
	language = {en},
	number = {6419},
	urldate = {2020-10-09},
	journal = {Science},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	month = dec,
	year = {2018},
	pmid = {30523106},
	note = {Publisher: American Association for the Advancement of Science
Section: Report},
	pages = {1140--1144},
	file = {Full Text PDF:/home/seb/Zotero/storage/GPL9CW4K/Silver et al. - 2018 - A general reinforcement learning algorithm that ma.pdf:application/pdf;Snapshot:/home/seb/Zotero/storage/ABQXVIA3/1140.html:text/html}
}

@article{nageswaran_configurable_2009,
	series = {Advances in {Neural} {Networks} {Research}: {IJCNN2009}},
	title = {A configurable simulation environment for the efficient simulation of large-scale spiking neural networks on graphics processors},
	volume = {22},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608009001373},
	doi = {10.1016/j.neunet.2009.06.028},
	abstract = {Neural network simulators that take into account the spiking behavior of neurons are useful for studying brain mechanisms and for various neural engineering applications. Spiking Neural Network (SNN) simulators have been traditionally simulated on large-scale clusters, super-computers, or on dedicated hardware architectures. Alternatively, Compute Unified Device Architecture (CUDA) Graphics Processing Units (GPUs) can provide a low-cost, programmable, and high-performance computing platform for simulation of SNNs. In this paper we demonstrate an efficient, biologically realistic, large-scale SNN simulator that runs on a single GPU. The SNN model includes Izhikevich spiking neurons, detailed models of synaptic plasticity and variable axonal delay. We allow user-defined configuration of the GPU-SNN model by means of a high-level programming interface written in C++ but similar to the PyNN programming interface specification. PyNN is a common programming interface developed by the neuronal simulation community to allow a single script to run on various simulators. The GPU implementation (on NVIDIA GTX-280 with 1 GB of memory) is up to 26 times faster than a CPU version for the simulation of 100K neurons with 50 Million synaptic connections, firing at an average rate of 7 Hz. For simulation of 10 Million synaptic connections and 100K neurons, the GPU SNN model is only 1.5 times slower than real-time. Further, we present a collection of new techniques related to parallelism extraction, mapping of irregular communication, and network representation for effective simulation of SNNs on GPUs. The fidelity of the simulation results was validated on CPU simulations using firing rate, synaptic weight distribution, and inter-spike interval analysis. Our simulator is publicly available to the modeling community so that researchers will have easy access to large-scale SNN simulations.},
	language = {en},
	number = {5},
	urldate = {2020-10-09},
	journal = {Neural Networks},
	author = {Nageswaran, Jayram Moorkanikara and Dutt, Nikil and Krichmar, Jeffrey L. and Nicolau, Alex and Veidenbaum, Alexander V.},
	month = jul,
	year = {2009},
	keywords = {STDP, CUDA, Data parallelism, Graphics processor, Izhikevich spiking neuron},
	pages = {791--800},
	file = {ScienceDirect Full Text PDF:/home/seb/Zotero/storage/JFA22LJC/Nageswaran et al. - 2009 - A configurable simulation environment for the effi.pdf:application/pdf;ScienceDirect Snapshot:/home/seb/Zotero/storage/GEKCZ76E/S0893608009001373.html:text/html}
}

@misc{anaconda_inc_numba_2012,
	title = {Numba for {CUDA} {GPUs} documentation},
	url = {https://numba.readthedocs.io/en/stable/cuda/index.html},
	urldate = {2020-10-13},
	author = {{Anaconda,~Inc.}},
	year = {2012},
	file = {Numba for CUDA GPUs — Numba 0.51.2-py3.7-linux-x86_64.egg documentation:/home/seb/Zotero/storage/LXD3D76D/index.html:text/html}
}

@misc{harris_chapter_2010,
	title = {Chapter 39. {Parallel} {Prefix} {Sum} ({Scan}) with {CUDA}},
	url = {https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda},
	language = {en},
	urldate = {2020-10-13},
	journal = {NVIDIA Developer},
	author = {Harris, Mark and Sengupta, Shubhabrata and Garland, Michael and Owens, John D.},
	year = {2010},
	file = {Snapshot:/home/seb/Zotero/storage/BYIEWBDR/chapter-39-parallel-prefix-sum-scan-cuda.html:text/html}
}

@techreport{blelloch_prefix_1990,
	address = {School of Computer Science},
	type = {Technical {Report}},
	title = {Prefix {Sums} and {Their} {Applications}},
	abstract = {Experienced algorithm designers rely heavily on a set of building blocks and on the tools needed to put the blocks together into an algorithm. The understanding of these basic blocks and tools is therefore critical to the understanding of algorithms. Many of the blocks and tools needed for parallel algorithms extend from sequential algorithms, such as dynamic-programming and divide-and-conquer, but others are new. This paper introduces one of the simplest and most useful building blocks for parallel algorithms: the all-pre xsums operation. The paper de nes the operation, shows how to implement it on a P-RAM and illustrates many applications of the operation. In addition to being a useful building block, the all-pre x-sums operation is a good example of a computation that seems inherently sequential, but for which there is an e cient parallel algorithm.},
	language = {en},
	number = {CMU-CS-90-190},
	institution = {Carnegie Mellon University},
	author = {Blelloch, Guy E},
	year = {1990},
	pages = {25},
	file = {Blelloch - Pre x Sums and Their Applications.pdf:/home/seb/Zotero/storage/CBKNWYIM/Blelloch - Pre x Sums and Their Applications.pdf:application/pdf}
}

@article{beyeler_gpu-accelerated_2015,
	series = {Neurobiologically {Inspired} {Robotics}: {Enhanced} {Autonomy} through {Neuromorphic} {Cognition}},
	title = {A {GPU}-accelerated cortical neural network model for visually guided robot navigation},
	volume = {72},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/S089360801500180X},
	doi = {10.1016/j.neunet.2015.09.005},
	abstract = {Humans and other terrestrial animals use vision to traverse novel cluttered environments with apparent ease. On one hand, although much is known about the behavioral dynamics of steering in humans, it remains unclear how relevant perceptual variables might be represented in the brain. On the other hand, although a wealth of data exists about the neural circuitry that is concerned with the perception of self-motion variables such as the current direction of travel, little research has been devoted to investigating how this neural circuitry may relate to active steering control. Here we present a cortical neural network model for visually guided navigation that has been embodied on a physical robot exploring a real-world environment. The model includes a rate based motion energy model for area V1, and a spiking neural network model for cortical area MT. The model generates a cortical representation of optic flow, determines the position of objects based on motion discontinuities, and combines these signals with the representation of a goal location to produce motor commands that successfully steer the robot around obstacles toward the goal. The model produces robot trajectories that closely match human behavioral data. This study demonstrates how neural signals in a model of cortical area MT might provide sufficient motion information to steer a physical robot on human-like paths around obstacles in a real-world environment, and exemplifies the importance of embodiment, as behavior is deeply coupled not only with the underlying model of brain function, but also with the anatomical constraints of the physical body it controls.},
	language = {en},
	urldate = {2020-10-14},
	journal = {Neural Networks},
	author = {Beyeler, Michael and Oros, Nicolas and Dutt, Nikil and Krichmar, Jeffrey L.},
	month = dec,
	year = {2015},
	keywords = {GPU, Motion energy, MT, Obstacle avoidance, Robot navigation, Spiking neural network},
	pages = {75--87},
	file = {ScienceDirect Full Text PDF:/home/seb/Zotero/storage/P6SLTL9E/Beyeler et al. - 2015 - A GPU-accelerated cortical neural network model fo.pdf:application/pdf;ScienceDirect Snapshot:/home/seb/Zotero/storage/NIIQW52H/S089360801500180X.html:text/html}
}

@article{yavuz_genn_2016,
	title = {{GeNN}: a code generation framework for accelerated brain simulations},
	volume = {6},
	copyright = {2016 The Author(s)},
	issn = {2045-2322},
	shorttitle = {{GeNN}},
	url = {https://www.nature.com/articles/srep18854},
	doi = {10.1038/srep18854},
	abstract = {Large-scale numerical simulations of detailed brain circuit models are important for identifying hypotheses on brain functions and testing their consistency and plausibility. An ongoing challenge for simulating realistic models is, however, computational speed. In this paper, we present the GeNN (GPU-enhanced Neuronal Networks) framework, which aims to facilitate the use of graphics accelerators for computational models of large-scale neuronal networks to address this challenge. GeNN is an open source library that generates code to accelerate the execution of network simulations on NVIDIA GPUs, through a flexible and extensible interface, which does not require in-depth technical knowledge from the users. We present performance benchmarks showing that 200-fold speedup compared to a single core of a CPU can be achieved for a network of one million conductance based Hodgkin-Huxley neurons but that for other models the speedup can differ. GeNN is available for Linux, Mac OS X and Windows platforms. The source code, user manual, tutorials, Wiki, in-depth example projects and all other related information can be found on the project website http://genn-team.github.io/genn/.},
	language = {en},
	number = {1},
	urldate = {2020-10-14},
	journal = {Scientific Reports},
	author = {Yavuz, Esin and Turner, James and Nowotny, Thomas},
	month = jan,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {18854},
	file = {Full Text PDF:/home/seb/Zotero/storage/9VTB7I9N/Yavuz et al. - 2016 - GeNN a code generation framework for accelerated .pdf:application/pdf;Snapshot:/home/seb/Zotero/storage/694BJSVT/srep18854.html:text/html}
}
